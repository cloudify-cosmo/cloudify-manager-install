// def waitForContainer(String container) {
//   echo "Waiting for ${container} to start"
//   sh "docker exec ${container} cfy_manager wait-for-starter"
// }
def configuration = [vaultUrl: "${VAULT_URL}",  vaultCredentialId: "vault-app-role", engineVersion: 2]

def secrets = [
  [path: 'secret/jenkins/cloudify', engineVersion: 2, secretValues: [
    [envVar: 'OS_USERNAME', vaultKey: 'username'],
    [envVar: 'OS_TENANT', vaultKey: 'tenant'],
    [envVar: 'OS_IP', vaultKey: 'ip'],
    [envVar: 'OS_PASSWORD', vaultKey: 'password']]],
]

@Library('pipeline-shared-library') _

pipeline {
  agent {
    kubernetes {
      label "manager-install-mb-${env.BUILD_NUMBER}"
      defaultContainer 'jnlp'
      yamlFile 'jenkins/build-pod.yaml'
    }
  }

  options {
    checkoutToSubdirectory('cloudify-manager-install')
    buildDiscarder(logRotator(numToKeepStr:'10'))
    timeout(time: 60, unit: 'MINUTES')
    timestamps()
  }

  environment {
    PROJECT = "cloudify-manager-install"
    WORKSPACE = "${env.WORKSPACE}"
    PATH = "/root/.local/bin:$PATH"
    VERSION = getVersion("master").trim()
    PRERELEASE = getPreRelease("master").trim()
    CLOUDIFY_VERSION = "${env.VERSION}"
    CLOUDIFY_PACKAGE_RELEASE = "${env.PRERELEASE}"
    S3_BUILD_PATH = "${env.VERSION}/${env.PRERELEASE}-build/${env.PROJECT}/${env.BRANCH_NAME}/${env.BUILD_NUMBER}"
  }
  stages{
    stage ('compatability and flake8') {
      parallel{
        stage ('py3_compat'){
          steps{
            sh script: "mkdir -p ${env.WORKSPACE}/py3_compat && cp -rf ${env.WORKSPACE}/${env.PROJECT}/. ${env.WORKSPACE}/py3_compat", label: "copying repo to seperate workspace"
            container('py27'){
              dir("${env.WORKSPACE}/py3_compat"){
                py3Compat()
              }
            }
          }
        }
        stage('flake8') {
          steps{
            sh script: "mkdir -p ${env.WORKSPACE}/flake8 && cp -rf ${env.WORKSPACE}/${env.PROJECT}/. ${env.WORKSPACE}/flake8", label: "copying repo to seperate workspace"
            container('py36'){
              dir("${env.WORKSPACE}/flake8") {
                echo 'install flake 8'
                sh 'pip install flake8 --user'
                echo 'run flake8'
                sh 'python -m flake8'
              }
            }
          }
        }
        stage('fetch_rpms') {
          steps {
            sh script:"mkdir -p ${env.WORKSPACE}/rpms", label: "creating RPMs folder"
            container('python') {
              dir("${env.WORKSPACE}/rpms") {
                echo 'Install requests'
                sh 'pip install requests'
                sh script:"""
                  curl https://cloudify-release-eu.s3.amazonaws.com/cloudify/${env.VERSION}/${env.PRERELEASE}-release/cloudify-rest-service-${env.VERSION}-${env.PRERELEASE}.el7.x86_64.rpm
                  curl https://cloudify-release-eu.s3.amazonaws.com/cloudify/${env.VERSION}/${env.PRERELEASE}-release/patroni-${env.VERSION}-${env.PRERELEASE}.el7.x86_64.rpm
                  curl https://cloudify-release-eu.s3.amazonaws.com/cloudify/${env.VERSION}/${env.PRERELEASE}-release/cloudify-premium-${env.VERSION}-${env.PRERELEASE}.el7.x86_64.rpm
                  curl https://cloudify-release-eu.s3.amazonaws.com/cloudify/${env.VERSION}/${env.PRERELEASE}-release/cloudify-cli-${env.VERSION}-${env.PRERELEASE}.el7.x86_64.rpm
                  curl https://cloudify-release-eu.s3.amazonaws.com/cloudify/${env.VERSION}/${env.PRERELEASE}-release/cloudify-agents-${env.VERSION}-${env.PRERELEASE}.el7.x86_64.rpm
                  curl https://cloudify-release-eu.s3.amazonaws.com/cloudify/${env.VERSION}/${env.PRERELEASE}-release/cloudify-management-worker-${env.VERSION}-${env.PRERELEASE}.el7.x86_64.rpm
                  curl https://cloudify-release-eu.s3.amazonaws.com/cloudify/${env.VERSION}/${env.PRERELEASE}-release/cloudify-manager-ip-setter-${env.VERSION}-${env.PRERELEASE}.el7.x86_64.rpm
                  curl https://cloudify-release-eu.s3.amazonaws.com/cloudify/${env.VERSION}/${env.PRERELEASE}-release/cloudify-rabbitmq-${env.VERSION}-${env.PRERELEASE}.el7.x86_64.rpm
                  """, label: 'Fetch RPM built on Jenkins located on S3'
              }
            }
          }
        }
        stage('build_prometheus_rpms') {
          steps {
            sh script: "mkdir -p ${env.WORKSPACE}/prometheus && cp -rf ${env.WORKSPACE}/${env.PROJECT}/. ${env.WORKSPACE}/prometheus", label: "copying repo to seperate workspace"
            container('rpmbuild') {
              dir("${env.WORKSPACE}/prometheus") {
                echo 'Link items from workspace under rpm sources dir'
                sh """
                  rm ~/rpm -fr
                  ln -s ${env.WORKSPACE}/rpms ./rpms
                  ln -s . ~/rpm
                  """
                echo 'Install rpmdevtools and build dependencies'
                sh '''
                  yum install rpmdevtools -y
                  yum-builddep -y packaging/install_rpm.spec
                  '''
                echo 'build rpms'
                sh '''
                  rpmbuild -bb packaging/prometheus.spec
                  rpmbuild -bb packaging/prometheus_node_exporter.spec
                  rpmbuild -bb packaging/prometheus_blackbox_exporter.spec
                  rpmbuild -bb packaging/prometheus_postgres_exporter.spec
                  '''
                sh script:("mkdir -p ${env.WORKSPACE}/prometheus-rpms && cp -rf /root/rpmbuild/RPMS/x86_64/*.x86_64.rpm ${env.WORKSPACE}/prometheus-rpms"), label:'Copy RPMS to rpms folder'
              }
            }
          }
          post {
            success {
              archiveArtifacts '**/prometheus-rpms/*.rpm'
            }
          }
        }
      }
    }
    stage('build_rpm & deploy ec2 instance') {
      parallel {
        stage('build_rpm') {
          steps {
            container('rpmbuild') {
              sh """
                cd && cd rpmbuild
                git clone --single-branch --branch ${env.BRANCH_NAME} https://github.com/cloudify-cosmo/cloudify-manager-install.git SOURCES && cd SOURCES
                """
              echo 'Setup Github SSH key'
              setupGithubSSHKey()
              echo 'Link items from workspace under rpm sources dir'
              sh """
                cd /root/rpmbuild/SOURCES
                rm ~/rpm -fr
                ln -s ${env.WORKSPACE}/rpms ./rpms
                cp -a ${env.WORKSPACE}/prometheus-rpms/prometheus-*.rpm ./rpms/
                cp -a ${env.WORKSPACE}/prometheus-rpms/*_exporter-*.rpm ./rpms/
                ln -s . ~/rpm
                """
              sh script: """
                pushd rpms
                  /root/rpmbuild/SOURCES/packaging/fetch_requirements --edition premium -b ${BRANCH_NAME} >~/fetch_requirements.log
                  cat ~/fetch_requirements.log
                popd
                """, label: 'fetching requirements'
              echo 'prepare to build rpm'
              sh '''
                yum install rpmdevtools -y
                chmod a+wx /opt
                '''
              echo 'Installing build dependencies'
              sh 'yum-builddep -y /root/rpmbuild/SOURCES/packaging/install_rpm.spec'
              echo 'set premium_edition in the packaged config.yaml'
              sh 'sed -i "s/set_by_installer_builder/premium/" /root/rpmbuild/SOURCES/config.yaml'
              echo 'Build RPM'
              sh """
                cd /root/rpmbuild/SOURCES/
                rpmbuild -D "CLOUDIFY_VERSION ${CLOUDIFY_VERSION}" \
                -D "CLOUDIFY_PACKAGE_RELEASE ${CLOUDIFY_PACKAGE_RELEASE}" \
                -bb packaging/install_rpm.spec
                """
              sh script:("mkdir -p ${env.WORKSPACE}/manager-rpm && cp -rf /root/rpmbuild/RPMS/x86_64/*-manager-*.x86_64.rpm ${env.WORKSPACE}/manager-rpm"), label:'Copy RPMS to rpms folder'
            }
          }
          post {
            success {
              archiveArtifacts '**/manager-rpm/*.rpm'
              echo 'Upload artifacts to S3'
              uploadToReleaseS3("${env.WORKSPACE}/manager-rpm/","${env.S3_BUILD_PATH}")
            }
          }
        }
        stage('Deploy ec2 instance'){
          steps {
            script {
              buildState = 'FAILURE'
              catchError(message: 'Failure on: manager-install EC2 Creation', buildResult: 'SUCCESS', stageResult: 'FAILURE') {
                container('py27') {
                  echo 'Setup Github SSH key'
                  setupGithubSSHKey()
                  dir("${env.WORKSPACE}/${env.PROJECT}/jenkins") {
                    withVault([configuration: configuration, vaultSecrets: secrets]){
                      sh script:"""#!/bin/bash
                      apt-get update
                      python -m ensurepip --upgrade
                      python -m pip install --upgrade pip
                      python -m pip install --upgrade virtualenv

                      virtualenv .venv
                      source .venv/bin/activate

                      pip install cloudify==5.1.0
                      cfy profile use ${env.OS_IP} -u ${env.OS_USERNAME} -p ${env.OS_PASSWORD} -t ${env.OS_TENANT}
                      pushd 'bp'
                        cfy install -b ec2-manager-install-blueprint-${env.BUILD_NUMBER} ec2-manager-install-blueprint.yaml
                      popd
                      cfy deployments capabilities ec2-manager-install-blueprint-${env.BUILD_NUMBER} --json > capabilities.json
                      echo -e \$(cat capabilities.json | jq '.key_content.value' | tr -d '"') > ~/.ssh/ec2_ssh_key && chmod 600 ~/.ssh/ec2_ssh_key
                      sleep 160
                      ssh-keyscan -H \$(cat capabilities.json | jq '.endpoint.value' | tr -d '"') >> ~/.ssh/known_hosts
                      echo 'ClientAliveInterval 50' | sudo tee --append /etc/ssh/sshd_config
                      """, label:'Configure and install blueprint on manager'
                    }
                  }
                }
              }
            }
          }             
        }
      }
    }
    // stage('Installations') {
      // parallel {
        stage('install_manager') {
          environment {
            CONTAINER_NAME = "cfy_aio"
            IMAGE_NAME = "cfy_manager_image"
          }
          steps {
            catchError(message: 'Failure on: manager-install install_manager', buildResult: 'SUCCESS', stageResult: 'FAILURE') {
              container('py27') {
                dir("${env.WORKSPACE}/${env.PROJECT}/jenkins") {
                  withVault([configuration: configuration, vaultSecrets: secrets]){
                    sh script: """#!/bin/bash
                    ssh -i ~/.ssh/ec2_ssh_key -l centos \$(cat capabilities.json | jq '.endpoint.value' | tr -d '"') /bin/bash << 'EOT'
sudo yum -y update
sudo service docker start
git clone https://github.com/cloudify-cosmo/cloudify-manager-install.git && cd cloudify-manager-install && git checkout ${env.BRANCH_NAME}
docker run --net host -dt -v ${pwd}:/mount python python -m http.server -d /mount
echo 'Build manager container'
set -eux
ls -la .
pushd packaging/docker
  docker build --network host --build-arg rpm_file=https://cloudify-release-eu.s3.amazonaws.com/cloudify/${env.S3_BUILD_PATH}/cloudify-manager-install-${env.VERSION}-${env.PRERELEASE}.el7.centos.x86_64.rpm --tag ${env.IMAGE_NAME} .
popd
echo 'Run manager container'
set -eux
docker run --name ${env.CONTAINER_NAME} -d -v /sys/fs/cgroup:/sys/fs/cgroup:ro --tmpfs /run --tmpfs /run/lock ${env.IMAGE_NAME}

""", label: 'install manager'
                  }
                }
              }
            }
          }
        }
        stage('install_cluster'){
          environment {
            CONTAINER_NAME = "cfy"
            IMAGE_NAME = "cfy_manager_image"
            CLUSTER_IMAGE = "cfy_manager_image_preinstalled"
          }
          steps {
            catchError(message: 'Failure on: manager-install install_cluster', buildResult: 'SUCCESS', stageResult: 'FAILURE') {
              container('py27') {
                dir("${env.WORKSPACE}/${env.PROJECT}/jenkins") {
                  withVault([configuration: configuration, vaultSecrets: secrets]) {
                    script {
                      def filename = 'config_env_three_nodes.yaml'
                      def data = readYaml file: filename

                      data.manager_rpm_download_link = "https://cloudify-release-eu.s3.amazonaws.com/cloudify/${env.S3_BUILD_PATH}/cloudify-manager-install-${env.VERSION}-${env.PRERELEASE}.el7.centos.x86_64.rpm"
                      sh "rm $filename"
                      writeYaml file: filename, data: data
                    }
                    sh script: """#!/bin/bash
                     ssh -i ~/.ssh/ec2_ssh_key -l centos \$(cat capabilities.json | jq '.endpoint.value' | tr -d '"') /bin/bash << 'EOT'
cd ~/cloudify-manager-install && git checkout ${env.BRANCH_NAME}
sudo docker network create --subnet=172.12.0.0/16 cluster_net
ssh-keygen -f ~/pkey.pem -P ""
pushd jenkins
  sudo docker build --tag sshcentos .
popd
sudo docker run -d --name cluster1 --net cluster_net --privileged --ip 172.12.0.3 sshcentos
sudo docker run -d --name cluster2 --net cluster_net --privileged --ip 172.12.0.4 sshcentos
sudo docker run -d --name cluster3 --net cluster_net --privileged --ip 172.12.0.5 sshcentos
sudo docker cp ~/pkey.pem cluster1:/root/pkey.pem
sudo docker cp ~/pkey.pem.pub cluster1:/root/.ssh/authorized_keys
sudo docker cp ~/pkey.pem.pub cluster2:/root/.ssh/authorized_keys
sudo docker cp ~/pkey.pem.pub cluster3:/root/.ssh/authorized_keys
sudo docker exec cluster1 yum install -y http://repository.cloudifysource.org/cloudify/cloudify-cluster-manager/1.0.3/ga-release/cloudify-cluster-manager-1.0.3-ga.el7.x86_64.rpm
sudo docker exec cluster1 yum install -y epel-release
sudo docker exec cluster1 yum install -y haveged
sudo docker exec cluster1 systemctl start haveged
sudo docker cp ${env.WORKSPACE}/${env.PROJECT}/jenkins/config_env_three_nodes.yaml cluster1:/cfy_cluster_config.yaml
sudo docker cp ${env.WORKSPACE}/${env.PROJECT}/jenkins/Dev-PS_cloudify_license.yaml cluster1:/root/Dev-PS_cloudify_license.yaml
ls ${env.WORKSPACE}/${env.PROJECT}/jenkins
sudo docker exec cluster1 ls /
sudo docker exec cluster1 ls /root/
sudo docker exec -d cluster1 /usr/sbin/sshd -D
sudo docker exec -d cluster2 /usr/sbin/sshd -D
sudo docker exec -d cluster3 /usr/sbin/sshd -D
sudo docker exec -i cluster1 cfy_cluster_manager install -v
"""
                  }
                }
              }
            }
          }
        }
      // }
    // }
    stage('Terminate py27 instnace'){
      steps{
        container('py27'){
          dir("${env.WORKSPACE}/${env.PROJECT}/jenkins"){
            withVault([configuration: configuration, vaultSecrets: secrets]){
              echo 'Uninstall and delete blueprint from manager'
              sh """#!/bin/bash
                source .venv/bin/activate
                cfy uninstall ec2-manager-install-blueprint-${env.BUILD_NUMBER} --force --allow-custom-parameters -p ignore_failures=true
              """
            }
          }
        }
      }
    }
  }
}