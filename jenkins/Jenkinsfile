def configuration = [vaultUrl: "${VAULT_URL}",  vaultCredentialId: "vault-app-role", engineVersion: 2]

def secrets = [
  [path: 'secret/jenkins/github', engineVersion: 2, secretValues: [
    [envVar: 'GITHUB_TOKEN', vaultKey: 'public_token'],
    [envVar: 'GITHUB_USERNAME', vaultKey: 'username']]],
  [path: 'secret/jenkins/jenkinstoken', engineVersion: 2, secretValues: [
    [envVar: 'JENKINS_USERNAME', vaultKey: 'username'],
    [envVar: 'JENKINS_TOKEN', vaultKey: 'token']]],
  [path: 'secret/jenkins/cloudifyaws', engineVersion: 2, secretValues: [
    [envVar: 'MANAGER_USERNAME', vaultKey: 'username'],
    [envVar: 'MANAGER_TENANT', vaultKey: 'tenant'],
    [envVar: 'MANAGER_IP', vaultKey: 'ip'],
    [envVar: 'MANAGER_PASSWORD', vaultKey: 'password']]],
]

@Library('pipeline-shared-library') _

def doGetVersion(){
  sh(script: '''#!/bin/sh -e
    . cloudify-manager-install/packaging/version_info
    echo ${CLOUDIFY_VERSION}
  ''', label: 'get package version', returnStdout: true).trim()
}

def doGetPreRelease(){
  sh(script: '''#!/bin/sh -e
    . cloudify-manager-install/packaging/version_info
    echo ${CLOUDIFY_PACKAGE_RELEASE}
  ''', label: 'get package release', returnStdout: true).trim()
}

pipeline {
  agent {
    kubernetes {
      defaultContainer 'jnlp'
      yamlFile 'jenkins/build-pod.yaml'
    }
  }

  options {
    checkoutToSubdirectory('cloudify-manager-install')
    buildDiscarder(logRotator(numToKeepStr:'10'))
    timeout(time: 60, unit: 'MINUTES')
    timestamps()
  }

  environment {
    PROJECT = "cloudify-manager-install"
    PATH = "/root/.local/bin:$PATH"
    VERSION = doGetVersion()
    PRERELEASE = doGetPreRelease()
    CLOUDIFY_VERSION = "${env.VERSION}"
    CLOUDIFY_PACKAGE_RELEASE = "${env.PRERELEASE}"
    CONTAINER_NAME = "cfy"
    CLUSTER_IMAGE = "cfy_manager_image_preinstalled"
    S3_BUILD_PATH = "${env.VERSION}/${env.PRERELEASE}-build/${env.PROJECT}/${env.BRANCH_NAME}/${env.BUILD_NUMBER}"
  }
  stages{
    stage ('compatability and flake8') {
      parallel{
        stage('flake8') {
          steps{
            sh script: "mkdir -p ${env.WORKSPACE}/flake8 && cp -rf ${env.WORKSPACE}/${env.PROJECT}/. ${env.WORKSPACE}/flake8", label: "copying repo to separate workspace"
            container('py311'){
              dir("${env.WORKSPACE}/flake8") {
                echo 'install flake 8'
                sh 'pip install flake8 --user'
                echo 'run flake8'
                sh 'python -m flake8'
              }
            }
          }
        }
        stage('tests') {
          steps{
            container('py311'){
              dir("${env.WORKSPACE}/${env.PROJECT}") {
                sh 'pip install pip setuptools --upgrade'
                sh 'pip install pytest --user'
                sh 'pip install . --user'
                sh 'pytest -svx cfy_manager'
              }
            }
          }
        }
        stage('fetch_rpms') {
          steps {
            sh script:"mkdir -p ${env.WORKSPACE}/rpms", label: "creating RPMs folder"
            container('python') {
              dir("${env.WORKSPACE}/rpms") {
                withVault([configuration: configuration, vaultSecrets: secrets]) {
                  echo 'Install requests'
                  sh 'pip install requests'
                  sh script:"""#!/bin/bash
                     source ${env.WORKSPACE}/${env.PROJECT}/packaging/source_branch
                     chmod +x ${env.WORKSPACE}/${env.PROJECT}/jenkins/fetch_rpms
                     ${env.WORKSPACE}/${env.PROJECT}/jenkins/fetch_rpms -d ${env.WORKSPACE}/rpms
                     """, label: 'Fetch RPM artifacts stored on Jenkins'
                }
              }
            }
          }
        }
        stage('build_prometheus_rpms') {
          steps {
            sh script: "mkdir -p ${env.WORKSPACE}/prometheus && cp -rf ${env.WORKSPACE}/${env.PROJECT}/. ${env.WORKSPACE}/prometheus", label: "copying repo to separate workspace"
            container('rpmbuild') {
              dir("${env.WORKSPACE}/prometheus") {
                echo 'Link items from workspace under rpm sources dir'
                sh """
                  rm ~/rpm -fr
                  ln -s ${env.WORKSPACE}/rpms ./rpms
                  ln -s . ~/rpm
                  """
                sh """
                  echo "Fix mirrorlist no longer available. See https://serverfault.com/questions/1161816/mirrorlist-centos-org-no-longer-resolve#answer-1161847"
                  find /etc/yum.repos.d/ -type f -name "*.repo" -print0 | xargs -0 sed -i s/mirror.centos.org/vault.centos.org/g

                  find /etc/yum.repos.d/ -type f -name "*.repo" -print0 | xargs -0 sed -i s/^#.*baseurl=http/baseurl=http/g
                  find /etc/yum.repos.d/ -type f -name "*.repo" -print0 | xargs -0 sed -i s/^mirrorlist=http/#mirrorlist=http/g
                """
                echo 'Install rpmdevtools and build dependencies'
                sh '''
                  yum-builddep -y packaging/install_rpm.spec
                  '''
                echo 'build rpms'
                sh """
                  for file in prometheus prometheus_node_exporter prometheus_postgres_exporter prometheus_blackbox_exporter; do
                    echo "build \$file rpm"
                    rpmbuild -D "arch amd64" -bb packaging/\$file.spec
                  done
                  """
                sh script:("mkdir -p ${env.WORKSPACE}/prometheus-rpms && cp -rf /root/rpmbuild/RPMS/x86_64/*.x86_64.rpm ${env.WORKSPACE}/prometheus-rpms"), label:'Copy RPMS to rpms folder'
              }
            }
          }
          post {
            success {
              archiveArtifacts '**/prometheus-rpms/*.rpm'
            }
          }
        }
      }
    }
    stage('build_rpm & deploy ec2 instance') {
      parallel {
        stage('build_rpm') {
          steps {
            container('rpmbuild') {
              sh """
                cd && cd rpmbuild
                git clone --single-branch --branch ${env.BRANCH_NAME} https://github.com/cloudify-cosmo/cloudify-manager-install.git SOURCES && cd SOURCES
                """
              echo 'Setup Github SSH key'
              setupGithubSSHKey()
              echo 'Link items from workspace under rpm sources dir'
              sh """
                cd /root/rpmbuild/SOURCES
                rm ~/rpm -fr
                ln -s ${env.WORKSPACE}/rpms ./rpms
                cp -a ${env.WORKSPACE}/prometheus-rpms/prometheus-*.rpm ./rpms/
                cp -a ${env.WORKSPACE}/prometheus-rpms/*_exporter-*.rpm ./rpms/
                ln -s . ~/rpm
                """
              sh script: """
                pushd rpms
                  /root/rpmbuild/SOURCES/packaging/fetch_requirements --edition premium -b ${BRANCH_NAME} --fallback-branch 7.0.5-build
                popd
                """, label: 'fetching requirements'
              echo 'prepare to build rpm'
              sh '''
                chmod a+wx /opt
                '''
              sh """
                echo "Fix mirrorlist no longer available. See https://serverfault.com/questions/1161816/mirrorlist-centos-org-no-longer-resolve#answer-1161847"
                find /etc/yum.repos.d/ -type f -name "*.repo" -print0 | xargs -0 sed -i s/mirror.centos.org/vault.centos.org/g

                find /etc/yum.repos.d/ -type f -name "*.repo" -print0 | xargs -0 sed -i s/^#.*baseurl=http/baseurl=http/g
                find /etc/yum.repos.d/ -type f -name "*.repo" -print0 | xargs -0 sed -i s/^mirrorlist=http/#mirrorlist=http/g
              """
              echo 'Installing build dependencies'
              sh 'yum-builddep -y /root/rpmbuild/SOURCES/packaging/install_rpm.spec'
              echo 'set premium_edition in the packaged config.yaml'
              sh 'sed -i "s/set_by_installer_builder/premium/" /root/rpmbuild/SOURCES/config.yaml'
              sh script: '''
                cd /root/rpmbuild/SOURCES/

                spectool \
                  -d "CLOUDIFY_VERSION ${CLOUDIFY_VERSION}" \
                  -d "CLOUDIFY_PACKAGE_RELEASE ${CLOUDIFY_PACKAGE_RELEASE}" \
                  -d "ARCHITECTURE x86_64" \
                  -P packaging/install_rpm.spec \
                  -S -g

                rpmbuild -D "CLOUDIFY_VERSION ${CLOUDIFY_VERSION}" \
                -D "CLOUDIFY_PACKAGE_RELEASE ${CLOUDIFY_PACKAGE_RELEASE}" \
                -D "ARCHITECTURE x86_64" \
                -bb packaging/install_rpm.spec
              ''', label: 'Build RPM'
              sh script:("mkdir -p ${env.WORKSPACE}/manager-rpm && cp -rf /root/rpmbuild/RPMS/x86_64/*-manager-*.x86_64.rpm ${env.WORKSPACE}/manager-rpm"), label:'Copy RPMS to rpms folder'
            }
          }
          post {
            success {
              echo 'Upload artifacts to S3'
              uploadToReleaseS3("${env.WORKSPACE}/manager-rpm/","${env.S3_BUILD_PATH}")
            }
          }
        }
        stage('Deploy ec2 instance'){
          steps {
            script {
              buildState = 'FAILURE'
              catchError(message: 'Failure on: manager-install EC2 Creation', buildResult: 'SUCCESS', stageResult: 'FAILURE') {
                container('py311') {
                  echo 'Setup Github SSH key'
                  setupGithubSSHKey()
                  dir("${env.WORKSPACE}/${env.PROJECT}/jenkins") {
                    withVault([configuration: configuration, vaultSecrets: secrets]){
                      sh script:"""#!/bin/bash
                      set -e
                      python -m venv .venv
                      source .venv/bin/activate
                      cfy profile use ${env.MANAGER_IP} -u ${env.MANAGER_USERNAME} -p ${env.MANAGER_PASSWORD} -t ${env.MANAGER_TENANT} --ssl
                      pushd 'bp'
                        cfy install -b ec2-manager-install-blueprint-${env.BUILD_NUMBER} ec2-manager-install-blueprint.yaml
                      popd
                      cfy deployments capabilities ec2-manager-install-blueprint-${env.BUILD_NUMBER} --json > capabilities.json
                      jq -r '.key_content.value' capabilities.json > ~/.ssh/ec2_ssh_key && chmod 600 ~/.ssh/ec2_ssh_key
                      sleep 160
                      ssh-keyscan -H \$(jq -r '.endpoint.value' capabilities.json) >> ~/.ssh/known_hosts
                      echo 'ClientAliveInterval 50' >> /etc/ssh/sshd_config
                      """, label:'Configure and install blueprint on manager'
                    }
                  }
                }
                // if We reach here that means everything is ok
                buildState = 'SUCCESS'
              }
            }
          }
        }
      }
    }
    stage ('Configure EC2 Instance') {
      when {
        expression { buildState != 'FAILURE'}
      }
      steps {
        script {
          buildState = 'FAILURE'
          catchError(message: 'Failure on: manager-install install manager', buildResult: 'SUCCESS', stageResult: 'FAILURE') {
            container('py311') {
              dir("${env.WORKSPACE}/${env.PROJECT}/jenkins") {
                withVault([configuration: configuration, vaultSecrets: secrets]) {
                  sh script: """#!/bin/bash
                  ssh -i ~/.ssh/ec2_ssh_key -l centos \$(cat capabilities.json | jq '.endpoint.value' | tr -d '"') /bin/bash << 'EOT'
                  sudo yum -y update
                  sudo service docker start
                  git clone https://github.com/cloudify-cosmo/cloudify-manager-install.git && cd cloudify-manager-install && git checkout ${env.BRANCH_NAME}
                  """, label: 'Configure EC2 Instance'
                }
              }
            }
            // if We reach here that means everything is ok
            buildState = 'SUCCESS'
          }
        }
      }
    }
    stage('install manager & cluster'){
      parallel{
        stage('install_manager') {
          when {
            expression { buildState != 'FAILURE'}
          }
          environment {
            CONTAINER_NAME = "cfy_aio"
            IMAGE_NAME = "cfy_manager_image"
          }
          steps {
            script{
              buildState = 'FAILURE'
              catchError(message: 'Failure on: manager-install install manager', buildResult: 'SUCCESS', stageResult: 'FAILURE') {
                container('py311') {
                  dir("${env.WORKSPACE}/${env.PROJECT}/jenkins") {
                    withVault([configuration: configuration, vaultSecrets: secrets]){
                      sh script: """#!/bin/bash
                      ssh -i ~/.ssh/ec2_ssh_key -l centos \$(cat capabilities.json | jq '.endpoint.value' | tr -d '"') /bin/bash << 'EOT'
cd ~/cloudify-manager-install
echo 'Build manager container'
set -eux
ls -la .
pushd packaging/docker-rh8
  docker build --network host --build-arg  rpm_file=https://cloudify-release-eu.s3.amazonaws.com/cloudify/${env.S3_BUILD_PATH}/cloudify-manager-install-${env.VERSION}-${env.PRERELEASE}.el8.x86_64.rpm --tag ${env.IMAGE_NAME} .
popd
pushd jenkins/Dockerfiles/test
  docker build -t test-manager-image .
popd
echo 'Run manager container'
set -eux
docker run --name ${env.CONTAINER_NAME} -d test-manager-image
echo "Waiting for ${env.CONTAINER_NAME} to start"
docker exec ${env.CONTAINER_NAME} cfy_manager wait-for-starter
echo 'Check Manager status'
sleep 40
sudo chmod +x jenkins/validate_status.sh
./jenkins/validate_status.sh ${env.CONTAINER_NAME}
echo 'Run the Sanity check'
sudo docker exec ${env.CONTAINER_NAME} cfy_manager sanity-check
""", label: 'install manager'
                    }
                  }
                }
                // if We reach here that means everything is ok
                buildState = 'SUCCESS'
              }
            }
          }
        }
        stage('install_cluster'){
          when {
            expression { buildState != 'FAILURE'}
          }
          environment {
            CONTAINER_NAME = "cfy"
            IMAGE_NAME = "cfy_manager_image"
          }
          steps {
           script{
            buildState = 'FAILURE'
            catchError(message: 'Failure on: manager-install install_cluster', buildResult: 'SUCCESS', stageResult: 'FAILURE') {
              container('py311') {
                dir("${env.WORKSPACE}/${env.PROJECT}/jenkins") {
                  withVault([configuration: configuration, vaultSecrets: secrets]) {
                    sh script: """#!/bin/bash
                    ssh -i ~/.ssh/ec2_ssh_key -l centos \$(cat capabilities.json | jq '.endpoint.value' | tr -d '"') /bin/bash << 'EOT'
cd ~/cloudify-manager-install
echo 'Build manager container'
set -eux
ls -la .
pushd packaging/docker-rh8
  docker build --network host --build-arg rpm_file=https://cloudify-release-eu.s3.amazonaws.com/cloudify/${env.S3_BUILD_PATH}/cloudify-manager-install-${env.VERSION}-${env.PRERELEASE}.el8.x86_64.rpm --tag ${env.IMAGE_NAME} .
popd
set -eux
pushd jenkins/cluster
  ./start_cluster.sh "${env.IMAGE_NAME}" "${env.CONTAINER_NAME}"
popd
echo 'Check cluster status'
sleep 40
sudo /home/centos/${env.PROJECT}/jenkins/validate_status.sh "${env.CONTAINER_NAME}_node1" "${env.CONTAINER_NAME}_node2" "${env.CONTAINER_NAME}_node3"
""", label: 'Prepare and run Cloudify cluster installation'
                    }
                  }
                }
                // if We reach here that means everything is ok
                buildState = 'SUCCESS'
              }
            }
          }
        }
      }
    }
    stage('Terminate EC2 instance'){
      steps{
        script{
          catchError(message: 'Failure on: Tearing down EC2 instance of manager-install ', buildResult: 'FAILURE', stageResult: 'FAILURE') {
            container('py311') {
              dir("${env.WORKSPACE}/${env.PROJECT}/jenkins"){
                withVault([configuration: configuration, vaultSecrets: secrets]) {
                  echo 'Uninstall and delete blueprint from manager'
                  sh """#!/bin/bash
                    source .venv/bin/activate
                    cfy uninstall ec2-manager-install-blueprint-${env.BUILD_NUMBER} --force --allow-custom-parameters -p ignore_failures=true
                  """
                }
              }
            }
          }
        }
      }
    }
  }
  post {
    always {
      findText(textFinders: [
        textFinder(regexp: 'Failure on:*', fileSet: '', alsoCheckConsoleOutput: true, buildResult: 'FAILURE')
        ]
      )
    }
  }
}
