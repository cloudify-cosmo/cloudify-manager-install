#! /usr/bin/env bash

SERVICE_MANAGER="{{service_manager}}"

check_patroni_log() {
  patroni_message=${1}
  if [[ "${SERVICE_MANAGER}" == "supervisord" ]]; then
       tail /var/log/cloudify/db_cluster/patroni.log | grep "${patroni_message}"
  else
       journalctl -u patroni | tail | grep "${patroni_message}"
  fi
}

run_service_command() {
  action=$1
  service_name=$2

  if [[ "${SERVICE_MANAGER}" == "supervisord" ]]; then
       supervisorctl -c /etc/supervisord.conf "${action}" "${service_name}"
  else
       systemctl "${action}" "${service_name}"
  fi
}

check_and_maybe_fix_patroni() {
  NODE_IP="{{ manager.private_ip }}"
  # Check whether patroni is started and has failed to start postgres
  # This may indicate that a (rare) issue has occurred where postgres can't be started properly...
  if run_service_command status patroni && check_patroni_log "Is another postmaster"; then
    echo "$(date): Initial startup is unhealthy, restarting and reinitializing." >> /var/log/cloudify/db_cluster/patroni/startup_check.log
    # ...so we will restart it and then ensure this node is properly repaired.
    run_service_command restart patroni
    cfy_manager dbs reinit -a ${NODE_IP}
  fi
}

while ! check_patroni_log "Future log output will appear"; do
  check_and_maybe_fix_patroni
  if check_patroni_log "Future log output will appear"; then
    echo "$(date): Waiting for patroni initial startup to complete healthily..." >> /var/log/cloudify/db_cluster/patroni/startup_check.log
    sleep 3
  fi
done

echo "$(date): Patroni initial startup complete." >> /var/log/cloudify/db_cluster/patroni/startup_check.log
